{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import boto3\n",
    "from boto3.s3.transfer import S3Transfer\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile():\n",
    "    \n",
    "    homepath = os.path.expanduser('~')\n",
    "    indicator_data = pd.read_csv('./Data/TimeSeries/Indicators_TimeSeries_Combined.csv', \\\n",
    "                                 low_memory=False)\n",
    "    return indicator_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing values for Argentina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argentina():\n",
    "    \n",
    "    indicator_data = readFile()\n",
    "\n",
    "    argentina_df_ind1 = indicator_data[(indicator_data['IndicatorCode'].isin(['AG.LND.AGRI.ZS'])) & \\\n",
    "                      (indicator_data['CountryCode'] == 'AR')]\n",
    "    argentina_df_ind2 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.DYN.CBRT.IN'])) & \\\n",
    "                      (indicator_data['CountryCode'] == 'AR')]\n",
    "    argentina_df_ind3 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.POP.DPND'])) & \\\n",
    "                      (indicator_data['CountryCode'] == 'AR')]\n",
    "    argentina_df_ind4 = indicator_data[(indicator_data['IndicatorCode'].isin(['NE.EXP.GNFS.ZS'])) & \\\n",
    "                      (indicator_data['CountryCode'] == 'AR')]\n",
    "    argentina_df_ind5 = indicator_data[(indicator_data['IndicatorCode'].isin(['NY.GDP.MKTP.CD'])) & \\\n",
    "                      (indicator_data['CountryCode'] == 'AR')]\n",
    "    argentina_df_ind6 = indicator_data[(indicator_data['IndicatorCode'].isin(['NY.GDP.MKTP.KD.ZG'])) & \\\n",
    "                      (indicator_data['CountryCode'] == 'AR')]\n",
    "    argentina_df_ind7 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.POP.GROW'])) & \\\n",
    "                      (indicator_data['CountryCode'] == 'AR')]\n",
    "    argentina_df_ind8 = indicator_data[(indicator_data['IndicatorCode'].isin(['FI.RES.TOTL.CD'])) & \\\n",
    "                      (indicator_data['CountryCode'] == 'AR')]\n",
    "    argentina_df_ind9 = indicator_data[(indicator_data['IndicatorCode'].isin(['NE.TRD.GNFS.ZS'])) & \\\n",
    "                      (indicator_data['CountryCode'] == 'AR')]\n",
    "\n",
    "\n",
    "    argentina_df_ind1['Value'] = argentina_df_ind1['Value'].interpolate()\n",
    "    argentina_df_ind1['Value'] = argentina_df_ind1['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    argentina_df_ind2['Value'] = argentina_df_ind2['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    argentina_df_ind5['Value'] = argentina_df_ind5['Value'].interpolate()\n",
    "\n",
    "    argentina_df_ind6['Value'] = argentina_df_ind6['Value'].interpolate()\n",
    "\n",
    "    # Combining all the Argentina Dataframes\n",
    "\n",
    "    Argentina_df = pd.concat([argentina_df_ind1, argentina_df_ind2, argentina_df_ind3, argentina_df_ind4, argentina_df_ind5,\\\n",
    "                          argentina_df_ind6, argentina_df_ind7, argentina_df_ind8, argentina_df_ind9])\n",
    "    print('Timeseries Wrangling completed for Argentina!!', '\\n')\n",
    "    return Argentina_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing values for Brazil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brazil():\n",
    "    \n",
    "    indicator_data = readFile()\n",
    "\n",
    "    brazil_df_ind1 = indicator_data[(indicator_data['IndicatorCode'].isin(['AG.LND.AGRI.ZS'])) &\\\n",
    "                                (indicator_data['CountryCode'] == 'BR')]\n",
    "    brazil_df_ind2 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.DYN.CBRT.IN'])) &\\\n",
    "                                (indicator_data['CountryCode'] == 'BR')]\n",
    "    brazil_df_ind3 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.POP.DPND'])) &\\\n",
    "                                (indicator_data['CountryCode'] == 'BR')]\n",
    "    brazil_df_ind4 = indicator_data[(indicator_data['IndicatorCode'].isin(['NE.EXP.GNFS.ZS'])) &\\\n",
    "                                (indicator_data['CountryCode'] == 'BR')]\n",
    "    brazil_df_ind5 = indicator_data[(indicator_data['IndicatorCode'].isin(['NY.GDP.MKTP.CD'])) &\\\n",
    "                                (indicator_data['CountryCode'] == 'BR')]\n",
    "    brazil_df_ind6 = indicator_data[(indicator_data['IndicatorCode'].isin(['NY.GDP.MKTP.KD.ZG'])) &\\\n",
    "                                (indicator_data['CountryCode'] == 'BR')]\n",
    "    brazil_df_ind7 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.POP.GROW'])) &\\\n",
    "                                (indicator_data['CountryCode'] == 'BR')]\n",
    "    brazil_df_ind8 = indicator_data[(indicator_data['IndicatorCode'].isin(['FI.RES.TOTL.CD'])) &\\\n",
    "                                (indicator_data['CountryCode'] == 'BR')]\n",
    "    brazil_df_ind9 = indicator_data[(indicator_data['IndicatorCode'].isin(['NE.TRD.GNFS.ZS'])) &\\\n",
    "                                (indicator_data['CountryCode'] == 'BR')]\n",
    "\n",
    "    brazil_df_ind1['Value'] = brazil_df_ind1['Value'].interpolate()\n",
    "    brazil_df_ind1['Value'] = brazil_df_ind1['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    brazil_df_ind2['Value'] = brazil_df_ind2['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    brazil_df_ind6['Value'] = brazil_df_ind6['Value'].interpolate()\n",
    "\n",
    "    # Combining all the Brazil Dataframes\n",
    "\n",
    "    Brazil_df = pd.concat([brazil_df_ind1, brazil_df_ind2, brazil_df_ind3, brazil_df_ind4, brazil_df_ind5,\\\n",
    "                       brazil_df_ind6, brazil_df_ind7, brazil_df_ind8, brazil_df_ind9])\n",
    "    print('Timeseries Wrangling completed for Brazil!!', '\\n')\n",
    "    return Brazil_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing values for Ecuador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecuador():\n",
    "    \n",
    "    indicator_data = readFile()\n",
    "\n",
    "    Ecuador_df_ind1 = indicator_data[(indicator_data['IndicatorCode'].isin(['AG.LND.AGRI.ZS'])) & \\\n",
    "                                 (indicator_data['CountryCode'] == 'EC')]\n",
    "    Ecuador_df_ind2 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.DYN.CBRT.IN'])) & \\\n",
    "                                 (indicator_data['CountryCode'] == 'EC')]\n",
    "    Ecuador_df_ind3 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.POP.DPND'])) & \\\n",
    "                                 (indicator_data['CountryCode'] == 'EC')]\n",
    "    Ecuador_df_ind4 = indicator_data[(indicator_data['IndicatorCode'].isin(['NE.EXP.GNFS.ZS'])) & \\\n",
    "                                 (indicator_data['CountryCode'] == 'EC')]\n",
    "    Ecuador_df_ind5 = indicator_data[(indicator_data['IndicatorCode'].isin(['NY.GDP.MKTP.CD'])) & \\\n",
    "                                 (indicator_data['CountryCode'] == 'EC')]\n",
    "    Ecuador_df_ind6 = indicator_data[(indicator_data['IndicatorCode'].isin(['NY.GDP.MKTP.KD.ZG'])) & \\\n",
    "                                 (indicator_data['CountryCode'] == 'EC')]\n",
    "    Ecuador_df_ind7 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.POP.GROW'])) & \\\n",
    "                                 (indicator_data['CountryCode'] == 'EC')]\n",
    "    Ecuador_df_ind8 = indicator_data[(indicator_data['IndicatorCode'].isin(['FI.RES.TOTL.CD'])) & \\\n",
    "                                 (indicator_data['CountryCode'] == 'EC')]\n",
    "    Ecuador_df_ind9 = indicator_data[(indicator_data['IndicatorCode'].isin(['NE.TRD.GNFS.ZS'])) & \\\n",
    "                                 (indicator_data['CountryCode'] == 'EC')]\n",
    "\n",
    "    Ecuador_df_ind1['Value'] = Ecuador_df_ind1['Value'].interpolate()\n",
    "    Ecuador_df_ind1['Value'] = Ecuador_df_ind1['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    Ecuador_df_ind2['Value'] = Ecuador_df_ind2['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    Ecuador_df_ind6['Value'] = Ecuador_df_ind6['Value'].interpolate()\n",
    "\n",
    "    # Combining all the Ecuador Dataframes\n",
    "\n",
    "    Ecuador_df = pd.concat([Ecuador_df_ind1, Ecuador_df_ind2, Ecuador_df_ind3, Ecuador_df_ind4, Ecuador_df_ind5,\\\n",
    "                          Ecuador_df_ind6, Ecuador_df_ind7, Ecuador_df_ind8, Ecuador_df_ind9])\n",
    "    \n",
    "    print('Timeseries Wrangling completed for Ecuador!!', '\\n')\n",
    "    return Ecuador_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing values for India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def india():\n",
    "    \n",
    "    indicator_data = readFile()\n",
    "\n",
    "    India_df_ind1 = indicator_data[(indicator_data['IndicatorCode'].isin(['AG.LND.AGRI.ZS'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'IN')]\n",
    "    India_df_ind2 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.DYN.CBRT.IN'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'IN')]\n",
    "    India_df_ind3 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.POP.DPND'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'IN')]\n",
    "    India_df_ind4 = indicator_data[(indicator_data['IndicatorCode'].isin(['NE.EXP.GNFS.ZS'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'IN')]\n",
    "    India_df_ind5 = indicator_data[(indicator_data['IndicatorCode'].isin(['NY.GDP.MKTP.CD'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'IN')]\n",
    "    India_df_ind6 = indicator_data[(indicator_data['IndicatorCode'].isin(['NY.GDP.MKTP.KD.ZG'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'IN')]\n",
    "    India_df_ind7 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.POP.GROW'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'IN')]\n",
    "    India_df_ind8 = indicator_data[(indicator_data['IndicatorCode'].isin(['FI.RES.TOTL.CD'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'IN')]\n",
    "    India_df_ind9 = indicator_data[(indicator_data['IndicatorCode'].isin(['NE.TRD.GNFS.ZS'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'IN')]\n",
    "\n",
    "    India_df_ind1['Value'] = India_df_ind1['Value'].interpolate()\n",
    "    India_df_ind1['Value'] = India_df_ind1['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    India_df_ind2['Value'] = India_df_ind2['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    India_df_ind6['Value'] = India_df_ind6['Value'].interpolate()\n",
    "\n",
    "    # Combining all the India Dataframes\n",
    "\n",
    "    India_df = pd.concat([India_df_ind1, India_df_ind2, India_df_ind3, India_df_ind4, India_df_ind5,\\\n",
    "                      India_df_ind6, India_df_ind7, India_df_ind8, India_df_ind9])\n",
    "    \n",
    "    print('Timeseries Wrangling completed for India!!', '\\n')\n",
    "    \n",
    "    return India_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing values for Libya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def libya():\n",
    "    \n",
    "    indicator_data = readFile()\n",
    "\n",
    "    Libya_df_ind1 = indicator_data[(indicator_data['IndicatorCode'].isin(['AG.LND.AGRI.ZS'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'LY')]\n",
    "    Libya_df_ind2 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.DYN.CBRT.IN'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'LY')]\n",
    "    Libya_df_ind3 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.POP.DPND'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'LY')]\n",
    "    Libya_df_ind4 = indicator_data[(indicator_data['IndicatorCode'].isin(['NE.EXP.GNFS.ZS'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'LY')]\n",
    "    Libya_df_ind5 = indicator_data[(indicator_data['IndicatorCode'].isin(['NY.GDP.MKTP.CD'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'LY')]\n",
    "    Libya_df_ind6 = indicator_data[(indicator_data['IndicatorCode'].isin(['NY.GDP.MKTP.KD.ZG'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'LY')]\n",
    "    Libya_df_ind7 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.POP.GROW'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'LY')]\n",
    "    Libya_df_ind8 = indicator_data[(indicator_data['IndicatorCode'].isin(['FI.RES.TOTL.CD'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'LY')]\n",
    "    Libya_df_ind9 = indicator_data[(indicator_data['IndicatorCode'].isin(['NE.TRD.GNFS.ZS'])) & \\\n",
    "                               (indicator_data['CountryCode'] == 'LY')]\n",
    "\n",
    "    Libya_df_ind1['Value'] = Libya_df_ind1['Value'].interpolate()\n",
    "    Libya_df_ind1['Value'] = Libya_df_ind1['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    Libya_df_ind2['Value'] = Libya_df_ind2['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    Libya_df_ind4['Value'] = Libya_df_ind4['Value'].interpolate()\n",
    "    Libya_df_ind4['Value'] = Libya_df_ind4['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    Libya_df_ind5['Value'] = Libya_df_ind5['Value'].interpolate()\n",
    "    Libya_df_ind5['Value'] = Libya_df_ind5['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    Libya_df_ind6['Value'] = Libya_df_ind6['Value'].interpolate()\n",
    "    Libya_df_ind6['Value'] = Libya_df_ind6['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    Libya_df_ind8['Value'] = Libya_df_ind8['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    Libya_df_ind9['Value'] = Libya_df_ind9['Value'].interpolate()\n",
    "    Libya_df_ind9['Value'] = Libya_df_ind9['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    # Combining all the Libya Dataframes\n",
    "\n",
    "    Libya_df = pd.concat([Libya_df_ind1, Libya_df_ind2, Libya_df_ind3, Libya_df_ind4, Libya_df_ind5,\\\n",
    "                      Libya_df_ind6, Libya_df_ind7, Libya_df_ind8, Libya_df_ind9])\n",
    "    \n",
    "    print('Timeseries Wrangling completed for Libya!!', '\\n')\n",
    "    \n",
    "    return Libya_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing values for South Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def south_Africa():\n",
    "    \n",
    "    indicator_data = readFile()\n",
    "\n",
    "    South_Africa_df_ind1 = indicator_data[(indicator_data['IndicatorCode'].isin(['AG.LND.AGRI.ZS'])) & \\\n",
    "                                      (indicator_data['CountryCode'] == 'ZA')]\n",
    "    South_Africa_df_ind2 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.DYN.CBRT.IN'])) & \\\n",
    "                                      (indicator_data['CountryCode'] == 'ZA')]\n",
    "    South_Africa_df_ind3 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.POP.DPND'])) & \\\n",
    "                                      (indicator_data['CountryCode'] == 'ZA')]\n",
    "    South_Africa_df_ind4 = indicator_data[(indicator_data['IndicatorCode'].isin(['NE.EXP.GNFS.ZS'])) & \\\n",
    "                                      (indicator_data['CountryCode'] == 'ZA')]\n",
    "    South_Africa_df_ind5 = indicator_data[(indicator_data['IndicatorCode'].isin(['NY.GDP.MKTP.CD'])) & \\\n",
    "                                      (indicator_data['CountryCode'] == 'ZA')]\n",
    "    South_Africa_df_ind6 = indicator_data[(indicator_data['IndicatorCode'].isin(['NY.GDP.MKTP.KD.ZG'])) & \\\n",
    "                                      (indicator_data['CountryCode'] == 'ZA')]\n",
    "    South_Africa_df_ind7 = indicator_data[(indicator_data['IndicatorCode'].isin(['SP.POP.GROW'])) & \\\n",
    "                                      (indicator_data['CountryCode'] == 'ZA')]\n",
    "    South_Africa_df_ind8 = indicator_data[(indicator_data['IndicatorCode'].isin(['FI.RES.TOTL.CD'])) & \\\n",
    "                                      (indicator_data['CountryCode'] == 'ZA')]\n",
    "    South_Africa_df_ind9 = indicator_data[(indicator_data['IndicatorCode'].isin(['NE.TRD.GNFS.ZS'])) & \\\n",
    "                                      (indicator_data['CountryCode'] == 'ZA')]\n",
    "\n",
    "    South_Africa_df_ind1['Value'] = South_Africa_df_ind1['Value'].interpolate()\n",
    "    South_Africa_df_ind1['Value'] = South_Africa_df_ind1['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    South_Africa_df_ind2['Value'] = South_Africa_df_ind2['Value'].fillna(method='bfill', axis = 0)\n",
    "\n",
    "    South_Africa_df_ind6['Value'] = South_Africa_df_ind6['Value'].interpolate()\n",
    "\n",
    "    # Combining all the South_Africa Dataframes\n",
    "\n",
    "    South_Africa_df = pd.concat([South_Africa_df_ind1, South_Africa_df_ind2, South_Africa_df_ind3, South_Africa_df_ind4,\\\n",
    "                             South_Africa_df_ind5, South_Africa_df_ind6, South_Africa_df_ind7, South_Africa_df_ind8, \\\n",
    "                             South_Africa_df_ind9])\n",
    "    \n",
    "    print('Timeseries Wrangling completed for South Africa!!', '\\n')\n",
    "    \n",
    "    return South_Africa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def writeFile():\n",
    "\n",
    "    Argentina_df = argentina()\n",
    "    Brazil_df = brazil()\n",
    "    Ecuador_df = ecuador()\n",
    "    India_df = india()\n",
    "    Libya_df = libya()\n",
    "    South_Africa_df = south_Africa()\n",
    "    \n",
    "    # Combining all countries DataFrame\n",
    "    final_df = pd.concat([Argentina_df, Brazil_df, Ecuador_df, India_df,\\\n",
    "                      Libya_df, South_Africa_df])\n",
    "\n",
    "    actual_filename = './Data/TimeSeries/Indicators_TimeSeries_Cleaned.csv'\n",
    "    final_df.to_csv(actual_filename, index=False)\n",
    "    \n",
    "    print('Timeseries Wrangling completed and file created!!', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileUploadToS3(AWS_ACCESS_KEY, AWS_SECRET_KEY):\n",
    "    \n",
    "    conn = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY)\n",
    "    transfer = S3Transfer(conn)\n",
    "\n",
    "    response = conn.list_buckets()    \n",
    "    existent = []\n",
    "    for bucket in response[\"Buckets\"]:\n",
    "        existent.append(bucket['Name'])\n",
    "\n",
    "    bucket_name = 'worlddevelopmentindicators'\n",
    "    target_dir = './Data/TimeSeries/'\n",
    "    filenames = []\n",
    "    file_list = os.listdir(target_dir)\n",
    "    for file in file_list:\n",
    "        if '_Cleaned' in file:\n",
    "            filenames.append(file)\n",
    "\n",
    "    if bucket_name in existent:\n",
    "        print('Bucket already exists!!', '\\n')\n",
    "        print('TimeSeries Cleaned File upload started to s3!!!!!', '\\n')\n",
    "        for files in filenames:\n",
    "            upload_filename = 'TimeSeries/'+files\n",
    "            transfer.upload_file(os.path.join(target_dir, files), bucket_name, upload_filename)\n",
    "        print('TimeSeries CLeaned File uploaded to s3!!!!!','\\n')\n",
    "            \n",
    "    else:\n",
    "        print('Bucket not present. Created bucket!!', '\\n')\n",
    "        conn.create_bucket(Bucket=bucket_name, ACL='public-read-write')\n",
    "        print('TimeSeries CLeaned File upload started to s3!!!!!', '\\n')\n",
    "        for files in filenames:\n",
    "            upload_filename = 'TimeSeries/'+files\n",
    "            transfer.upload_file(os.path.join(target_dir, files), bucket_name, upload_filename)\n",
    "        print('TimeSeries Cleaned File uploaded to s3!!!!!','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    user_input = sys.argv[1:]\n",
    "    print(\"----Process Started----\")\n",
    "    counter = 0\n",
    "    if len(user_input) == 0:\n",
    "        print('No Input provided. Process is exiting!!')\n",
    "        exit(0)\n",
    "    for ip in user_input:\n",
    "        if counter == 0:\n",
    "            AWS_ACCESS_KEY = str(ip)\n",
    "        else:\n",
    "            AWS_SECRET_KEY = str(ip)\n",
    "        counter += 1\n",
    "    \n",
    "    readFile()\n",
    "    writeFile()\n",
    "    fileUploadToS3('AKIAJEYOARR4SIMN7MIQ', 'i1CN2iogVbxR0RDSfFBS64xqbJ3On/jE9fW1mLVd')\n",
    "    \n",
    "    print('Timeseries Wrangling Process completed!!','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Process Started----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeseries Wrangling completed for Argentina!! \n",
      "\n",
      "Timeseries Wrangling completed for Brazil!! \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeseries Wrangling completed for Ecuador!! \n",
      "\n",
      "Timeseries Wrangling completed for India!! \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeseries Wrangling completed for Libya!! \n",
      "\n",
      "Timeseries Wrangling completed for South Africa!! \n",
      "\n",
      "Timeseries Wrangling completed and file created!! \n",
      "\n",
      "Bucket already exists!! \n",
      "\n",
      "TimeSeries Cleaned File upload started to s3!!!!! \n",
      "\n",
      "TimeSeries CLeaned File uploaded to s3!!!!! \n",
      "\n",
      "Timeseries Wrangling Process completed!! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
